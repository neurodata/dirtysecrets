# dirtysecrets
dirty secrets of data science


## hypothesis testing

1. frequentist theory is fundamentally flawed
2. bayesian theory is fundamentally flawed
3. t-test are not what you want
4. p-values are fine
8. hypothesis testing is estimating mutual information
13. your permutation test makes some assumptions


## estimation

12. you didn't want the mean or variance anway
15. high-dimensional statistics is impossible - you need to embed in a low dimensional space (implicitly or explicitly)
16. we have no model of vision, audition, or anything but Euclidean


## unsupervised learning

5. you didn't estimate the true number of clusters
6. kmeans is secretly gaussian mixture modeling
9. you didn't do better than PCA
10. manifold learning is nonsense
11. operating in the lower dimensional space isn't always better

## supervised learning

6. sparse models don't work
7. your deep net is not a universal function approximator, and even if it was, that's not what you wanted anyway
16. we have no model of vision, audition, or anything but Euclidean
1. just use random forest

## existing stuff doesn't work

1. build compelling evidence that existing tools don't work well/easily
2. pseudocode your new plan
3. build compelling evidence that your new thing does work in simulated settings where their thing doesn't work
3. build compelling evidence that your new thing does *not* work in simulated settings where their thing does work
4. build compelling evidence that your new thing is useful *scientifically*







